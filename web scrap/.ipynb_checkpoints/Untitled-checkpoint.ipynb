{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2902e436-8734-4e3c-873a-306fa2bd80c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import requests\n",
    "import re\n",
    "import sqlite3\n",
    "import time\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a7dd0d-83e4-416b-add2-8829b3a3c159",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________\n",
      "Page 1/100 completed. ETA : 24m 52s.\n",
      "________________________________\n",
      "Page 2/100 completed. ETA : 24m 2s.\n",
      "________________________________\n",
      "Page 3/100 completed. ETA : 23m 44s.\n",
      "________________________________\n",
      "Page 4/100 completed. ETA : 23m 21s.\n",
      "________________________________\n",
      "Page 5/100 completed. ETA : 23m 13s.\n",
      "________________________________\n",
      "Page 6/100 completed. ETA : 23m 0s.\n",
      "________________________________\n",
      "Page 7/100 completed. ETA : 22m 57s.\n",
      "________________________________\n",
      "Page 8/100 completed. ETA : 22m 47s.\n",
      "________________________________\n",
      "Page 9/100 completed. ETA : 22m 42s.\n",
      "________________________________\n",
      "Page 10/100 completed. ETA : 22m 34s.\n",
      "________________________________\n",
      "Page 11/100 completed. ETA : 22m 20s.\n",
      "________________________________\n",
      "Page 12/100 completed. ETA : 22m 10s.\n",
      "________________________________\n",
      "Page 13/100 completed. ETA : 21m 59s.\n",
      "________________________________\n",
      "Page 14/100 completed. ETA : 21m 46s.\n",
      "________________________________\n",
      "Page 15/100 completed. ETA : 21m 35s.\n",
      "________________________________\n",
      "Page 16/100 completed. ETA : 21m 27s.\n",
      "________________________________\n",
      "Page 17/100 completed. ETA : 21m 12s.\n",
      "________________________________\n",
      "Page 18/100 completed. ETA : 20m 59s.\n",
      "________________________________\n",
      "Page 19/100 completed. ETA : 20m 44s.\n",
      "________________________________\n",
      "Page 20/100 completed. ETA : 20m 32s.\n",
      "________________________________\n",
      "Page 21/100 completed. ETA : 20m 16s.\n",
      "________________________________\n",
      "Page 22/100 completed. ETA : 20m 3s.\n",
      "________________________________\n",
      "Page 23/100 completed. ETA : 19m 50s.\n",
      "________________________________\n",
      "Page 24/100 completed. ETA : 20m 9s.\n",
      "________________________________\n",
      "Page 25/100 completed. ETA : 20m 9s.\n",
      "________________________________\n",
      "Page 26/100 completed. ETA : 19m 53s.\n",
      "________________________________\n",
      "Page 27/100 completed. ETA : 19m 36s.\n",
      "________________________________\n",
      "Page 28/100 completed. ETA : 19m 21s.\n",
      "________________________________\n",
      "Page 29/100 completed. ETA : 19m 6s.\n",
      "________________________________\n",
      "Page 30/100 completed. ETA : 18m 49s.\n",
      "________________________________\n",
      "Page 31/100 completed. ETA : 18m 33s.\n",
      "________________________________\n",
      "Page 32/100 completed. ETA : 18m 18s.\n",
      "________________________________\n",
      "Page 33/100 completed. ETA : 18m 3s.\n",
      "________________________________\n",
      "Page 34/100 completed. ETA : 17m 46s.\n",
      "________________________________\n",
      "Page 35/100 completed. ETA : 17m 31s.\n",
      "________________________________\n",
      "Page 36/100 completed. ETA : 17m 16s.\n",
      "________________________________\n",
      "Page 37/100 completed. ETA : 17m 3s.\n",
      "________________________________\n",
      "Page 38/100 completed. ETA : 16m 47s.\n",
      "________________________________\n",
      "Page 39/100 completed. ETA : 16m 31s.\n",
      "________________________________\n",
      "Page 40/100 completed. ETA : 16m 13s.\n",
      "________________________________\n",
      "Page 41/100 completed. ETA : 15m 56s.\n",
      "________________________________\n",
      "Page 42/100 completed. ETA : 15m 41s.\n",
      "_________________"
     ]
    }
   ],
   "source": [
    "Id = []\n",
    "Title = []\n",
    "Time_ = []\n",
    "Type = []\n",
    "Duration = []\n",
    "ImgLink = []\n",
    "\n",
    "movieDesc = []\n",
    "Released = []\n",
    "Genre = []\n",
    "Casts = []\n",
    "Country = []\n",
    "Production = []\n",
    "IMDB_rating = []\n",
    "Cover_bg = []\n",
    "\n",
    "# Scraping settings\n",
    "type = \"movie\"\n",
    "quality = \"all\"\n",
    "year = \"all\"\n",
    "country = \"all\"\n",
    "genre = \"all\"\n",
    "\n",
    "headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/111.0.0.0 Safari/537.36'}\n",
    "\n",
    "# Start timer\n",
    "start_time = time.time()\n",
    "\n",
    "r1,r2 = 0 ,100\n",
    "id= r1\n",
    "\n",
    "total_pages = r2 -r1\n",
    "\n",
    "\n",
    "for i in range(r1,r2):\n",
    "    url = f\"https://moviesjoy.is/filter?type={type}&quality={quality}&release_year={year}&genre={genre}&country={country}&page={i+1}\"\n",
    "\n",
    "    # Fetch the webpage\n",
    "    webpage = requests.get(url, headers=headers).text\n",
    "    soup = BeautifulSoup(webpage, 'lxml')\n",
    "    \n",
    "    # Extract movies\n",
    "    movie = soup.find_all('div', class_='flw-item')\n",
    "    \n",
    "    # Time for each iteration\n",
    "    iteration_start = time.time()\n",
    "\n",
    "    for m in movie:\n",
    "        \n",
    "        try:\n",
    "\n",
    "            Movie_Link = m.find('a').get('href')\n",
    "            Movi_Url = f\"https://moviesjoy.is{Movie_Link}\"\n",
    "            moviePage = requests.get(Movi_Url, headers=headers).text\n",
    "            soup1 = BeautifulSoup(moviePage, 'lxml')\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "        Id.append(id)\n",
    "        id = id+1\n",
    "        Title.append(m.find('a').get('title'))\n",
    "        Time_.append(m.find(class_='fdi-item').text.strip())\n",
    "        Type.append(m.find(class_='fdi-type').text.strip())\n",
    "        Duration.append(m.find(class_='fdi-duration').text.strip())\n",
    "        ImgLink.append(m.find('div', class_='film-poster').find('img').get('data-src'))\n",
    "        \n",
    "        try:\n",
    "            style = soup1.find('div', class_='cover_follow')['style']\n",
    "            Cover_bg.append(re.search('url\\((.*)\\)', style)[1])\n",
    "        except:\n",
    "            Cover_bg.append(\"Na\")\n",
    "\n",
    "        try:\n",
    "            movieDesc.append(soup1.find('div', class_='description').text.strip())        \n",
    "        except:\n",
    "            movieDesc.append(\"Na\")\n",
    "        \n",
    "        try:\n",
    "            IMDB_rating.append(re.split('IMDB:', soup1.find('button', class_='btn-imdb').text)[1].strip(' '))\n",
    "        except:\n",
    "            IMDB_rating.append(\"Na\")\n",
    "        \n",
    "        data_div = str(soup1.find_all('div', class_='row-line'))\n",
    "\n",
    "        try:\n",
    "            Genre.append(re.findall('genre/([^\"]+)', data_div))        \n",
    "        except:\n",
    "            Genre.append(\"Na\")\n",
    "\n",
    "        try:\n",
    "            Casts.append(re.findall('cast/([^\"]+)', data_div))        \n",
    "        except:\n",
    "            Casts.append(\"Na\")\n",
    "\n",
    "        try:\n",
    "            Released.append(re.split('Released:\\s</strong></span>([^<]+)', str(data_div))[1].strip(\" \").strip('\\n'))\n",
    "        except:\n",
    "            Released.append('Na')\n",
    "\n",
    "        try:\n",
    "            Production.append(re.findall('/production/([^\"]+)', data_div)) \n",
    "        except: \n",
    "            Production.append('Na')\n",
    "        \n",
    "        try:\n",
    "            Country.append(re.split('/country/([^\"]+)', data_div)[1])\n",
    "        except:\n",
    "            Country.append(\"Na\")\n",
    "        \n",
    "        # Progress indicator for each movie\n",
    "        sys.stdout.write('_')\n",
    "        sys.stdout.flush()\n",
    "    \n",
    "    # Calculate time taken for this iteration\n",
    "    iteration_end = time.time()\n",
    "    time_taken = iteration_end - iteration_start\n",
    "    \n",
    "    # Estimate total time remaining\n",
    "    time_elapsed = time.time() - start_time\n",
    "    estimated_total_time = (time_elapsed / (i + 1)) * total_pages\n",
    "    estimated_remaining_time = estimated_total_time - time_elapsed\n",
    "\n",
    "    # Print the progress\n",
    "    sys.stdout.write(f\"\\nPage {i + 1}/{total_pages} completed. ETA : {int(estimated_remaining_time // 60)}m {int(estimated_remaining_time % 60)}s.\\n\")\n",
    "    sys.stdout.flush()\n",
    "\n",
    "# Total time taken\n",
    "total_time_taken = time.time() - start_time\n",
    "print(f\"\\nScraping completed in {int(total_time_taken // 60)} minutes {int(total_time_taken % 60)} seconds.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a0e8211-9d2b-46d5-a551-0f68a48ea529",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv(\"movie.csv\",index=False, header=False , mode='a')\n",
    "df.to_csv(\"movie.csv\",index=False, header=True )\n",
    "print(\"CSV file created successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "50c0eb49-4dbb-4b28-8b20-e5c74e3f808d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "columns = ['Id','Title' ,'Time' ,'Type', 'Duration', 'Img' ,'CoverBg','movieDesc', 'Released' ,'Genre' ,'Casts' ,'Country', 'Production' ,'IMDB_rating']\n",
    "pair = [pair for pair in zip(Id,Title ,Time_ ,Type ,Duration, ImgLink ,Cover_bg, movieDesc ,Released ,Genre ,Casts, Country ,Production ,IMDB_rating)]\n",
    "df = pd.DataFrame(pair, columns=columns )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b1d1c19b-c30a-46c6-b1e1-c042b0e9418d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file created successfully!\n"
     ]
    }
   ],
   "source": [
    "# df.to_csv(\"movie.csv\",index=False, header=False , mode='a')\n",
    "df.to_csv(\"movie.csv\",index=False, header=True )\n",
    "print(\"CSV file created successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f973c0c7-0c30-43d4-b2b7-593654dd5c0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35020961-df92-4967-950a-6cfc8b147a26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "92e2bbf0-4fa6-4734-a8bb-fe1deceebddc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d925437-8c9e-4174-885d-256aa823b9cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc9a7d1a-a5bf-4154-a844-b2f9db1af5f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b13716f7-4151-4979-8f47-81a664334536",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f8f28402-78bb-4138-a25a-099e360e71fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db815ca-8e94-4cb6-b762-8a00293e8e57",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
